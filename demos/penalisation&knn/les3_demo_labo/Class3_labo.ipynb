{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning- regression- knn and penalisation\n",
    "\n",
    "We work further on the same dataset as last labo: the housing dataset. The first steps (looking at the data, test/train-split and standardisation are already done for you in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "df = pd.read_csv('real_estate_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Take a look at the data\n",
    "\n",
    "Explore the data, as usual.\n",
    "1. Look at the dimensions of the dataset\n",
    "2. Look at the first lines of the dataset\n",
    "3. Get an overview of the features and their datatype\n",
    "4. Convert the dummy features to uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first few lines of dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an overview of the features and their datatype\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dummy features to type uint8\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Train/test-split and standardisation\n",
    "\n",
    "1. Shuffle your data\n",
    "\n",
    "2. Make a Train/test \n",
    "    - Use random state=123 whenever needed\n",
    "    - Use a test size of 20%\n",
    "    \n",
    "3. Standardize both datasets  \n",
    "    + Make sure you only standardise the numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Nearest neighbors\n",
    "## 3.1. Radius Neighbors Regression\n",
    "\n",
    "1. Perform a crossvalidation, using radius neighbors regression, with the radius ranging from 1 to 10\n",
    "    + Does it work?\n",
    "    + Why (not)?\n",
    "2. Search for the minimum radius that does work and do a crossvalidation with 10 values. \n",
    "    + E.g if it works at radius 5, let the radius range from 5 to 15.\n",
    "    + Draw a plot that plots the radius against the R2\n",
    "    + Is your best model a good model: is it underfitted or overfitted?\n",
    "    + Is RNN a good method to use when there are a lot of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crossvalidation from 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Radius = np.linspace(1,10,10)    # This will give an array of numbers between 1 and 10\n",
    "cv_scores = []\n",
    "sd_scores = []\n",
    "\n",
    "# perform 5-fold cross validation on the 10 possible values for the radius (bandwith)\n",
    "for k in Radius:\n",
    "    Rnn = RadiusNeighborsRegressor(radius= ...)\n",
    "    scores = cross_val_score(Rnn, ..., ...,  cv=5)\n",
    "    # store the average score\n",
    "    cv_scores.append(scores. ...())\n",
    "    # store the standard deviation of the score\n",
    "\n",
    "    sd_scores. ...(np.sqrt(scores.var())/np.sqrt(5))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crossvalidation that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "Radius = ...   \n",
    "cv_scores = ...\n",
    "sd_scores = ...\n",
    "\n",
    "for k in Radius:\n",
    "    Rnn = ...\n",
    "    scores = ...\n",
    "    cv_scores.append(...)\n",
    "    sd_scores.append(...)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "## First determine the maximum value and its index  \n",
    "max_value = ...(cv_scores)\n",
    "max_index = cv_scores. ...(max_value)\n",
    "\n",
    "# Plit the radius versus the cv_scores\n",
    "plt.plot(..., ...)\n",
    "plt.xlabel('Radius of Neighbors ')\n",
    "plt.ylabel('R^2')\n",
    "\n",
    "# plot the lower limit (max - 1.96 * sd.dev)\n",
    "plt.axhline(y= ... -1.96* ...[...])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 K-nearest Neighbors\n",
    "1. Perform a crossvalidation, using k-nearest neighbors regression, with k ranging from 1 to 65\n",
    "    \n",
    "2. Plot the number of neighbors (k) to the R2\n",
    "    + Also draw the lower boundary of the confidene interval of the maximum R2(maximum R2 - 1.96 * sd(of maximum R2) )\n",
    "    + First do a general plot\n",
    "    + Then zoom in on the highest values \n",
    "    + Which k leads to the highest R2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "K = np.arange(1,65)    \n",
    "cv_scores = []\n",
    "sd_scores = []\n",
    "# perform 5-fold cross validation on the  possible values for the radius (bandwith)\n",
    "for k in K:\n",
    "    knn = KNeighborsRegressor(n_neighbors= ...)\n",
    "    scores = ...\n",
    "    ...\n",
    "    ...\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = ...\n",
    "max_index = ...\n",
    "\n",
    "plt.plot(..., ...)\n",
    "plt.xlabel('k Neighbors ')\n",
    "plt.ylabel('R^2')\n",
    "plt.axhline(y=...)\n",
    "\n",
    "plt.show()\n",
    "print('The best k is', K[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is hard to read, so lets zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(K[... : ...],cv_scores[... : ...])\n",
    "plt.xlabel('k Neighbors ')\n",
    "plt.ylabel('R^2')\n",
    "\n",
    "plt.axhline(...)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print('The best k is', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Retrain and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on full training dataset and test on test-set\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=...)\n",
    "knn.fit(..., ...)  \n",
    "print('train value for k=5:', knn.score(..., ...) )\n",
    "print('test value for k=5:',... )\n",
    "\n",
    "# Retrain on full training dataset and test on test-set\n",
    "\n",
    "knn = ...\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Penalisation\n",
    "\n",
    "Untill know, we have seen that polynomial regression  leads to overfitting and knn leads to underfitting on this dataset, because of the curse of high dimensionality. Now, we will try a different approach, namely combining polynomial regression with penalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design polynomial features with degree 3\n",
    "    + Don't forget to also transform the test data\n",
    "    + Check the number of features of the new datasets: are there more observations or more features?\n",
    "2. Do lasso-penalisation, using the default alpha. \n",
    "    + Use linear_model.Lasso()\n",
    "    + Test on train and test set\n",
    "    + Is the model overfitted or underfitted?   \n",
    "    + Look at the coefficients. Does this explain the overfitting or underfitting?\n",
    "3. Do a cross-validation to find the best value for alpha. Let the function choose the values for alpha itself.\n",
    "    +  Would you say this model is overfitted, underfitted or neither?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(...)\n",
    "X_train_poly = ...\n",
    "X_test_poly = ...\n",
    "X_train_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lasso-penalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "linreg_lasso1 = linear_model.Lasso()\n",
    "linreg_lasso1.fit(..., ...)\n",
    "print('R2: %.3f' % linreg_lasso1.score(... , ...))\n",
    "print('R2: %.3f' % linreg_lasso1.score(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the coefficients (use .coef_)\n",
    "linreg_lasso1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "linreg_lassoCV = LassoCV(cv=5, random_state=123, max_iter=5000)\n",
    "linreg_lassoCV.fit(...)\n",
    "\n",
    "#results training\n",
    "print('R2 : %.3f' % linreg_lassoCV.score(..., ...))\n",
    "\n",
    "# results test\n",
    "print('R2 : %.3f' % ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this takes some time to run. Also note that applying the score function to the object containing the cross-validation automatically fits the best model from the CV! This saves us some work. You can ask for the value if you want to know it ofcourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for the alpha value of the best model (.alpha_)\n",
    "linreg_lassoCV.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for the training and test set\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
